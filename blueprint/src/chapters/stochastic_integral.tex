\chapter{Stochastic integral}

The lecture notes at \href{https://dec41.user.srcf.net/h/III_L/stochastic_calculus_and_applications/}{this link} as well as chapter 18 of \cite{kallenberg2021} are good references for this chapter.

\section{Total variation and Lebesgue-Stieltjes integral}

TODO: in Mathlib, we can integrate with respect to the measure given by a right-continuous monotone function (\texttt{StieltjesFunction.measure}). This will be useful to integrate against the quadratic variation of a local martingale.
However, we will also want to integrate with respect to a signed measure given by a càdlàg function with finite variation.
We need to investigate what's already in Mathlib. See \texttt{Mathlib.Topology.EMetricSpace.BoundedVariation}.



\section{Square integrable martingales}



\section{Local martingales}

TODO: filtrations should be assumed right-continuous and complete whenever needed.

TODO: this section follows Kallenberg's book and uses $\mathbb{R}_+$ as the time index.
Some of the definitions and results could possibly be generalized.

In this section, $E$ denotes a complete normed space.

First, recall the definitions of a martingale, a stopping time and a stopped process, which are already in Mathlib.


\begin{definition}\label{def:Martingale}
  \mathlibok
  \lean{MeasureTheory.Martingale}
Let $\mathcal{F}$ be a filtration on a measurable space $\Omega$ with measure $P$ indexed by $T$.
A family of functions $M : T \to \Omega \to E$ is a martingale with respect to a filtration $\mathcal{F}$ if $M$ is adapted with respect to $\mathcal{F}$ and for all $i \le j$, $P[M_j \mid \mathcal{F}_i] = M_i$ almost surely.
\end{definition}


\begin{definition}\label{def:IsStoppingTime}
  \mathlibok
  \lean{MeasureTheory.IsStoppingTime}
A stopping time with respect to some filtration $\mathcal{F}$ indexed by $T$ is a function $\tau : \Omega \to T$ such that for all $i$, the preimage of $\{j \mid j \le i\}$ along $\tau$ is measurable with respect to $\mathcal{F}_i$.
\end{definition}


\begin{definition}\label{def:stoppedProcess}
  \mathlibok
  \lean{MeasureTheory.stoppedProcess}
Let $X : T \to \Omega \to E$ be a stochastic process and let $\tau : \Omega \to T$.
The stopped process with respect to $\tau$ is defined by
\begin{align*}
  (X^{\tau})_t = \begin{cases}
    X_t & \text{if } t \le \tau \\
    X_{\tau} & \text{otherwise}
  \end{cases}
\end{align*}
\end{definition}


\begin{definition}\label{def:localMartingale}
  \uses{def:Martingale, def:IsStoppingTime, def:stoppedProcess}
Let $\mathcal{F} = (\mathcal{F}_t)_{t \in \mathbb{R}_+}$ be a filtration on a measurable space $\Omega$.
A local martingale with respect to $\mathcal{F}$ is a stochastic process $M : \mathbb{R}_+ \to \Omega \to E$ adapted to $\mathcal{F}$ such that there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that the following conditions hold:
\begin{itemize}
  \item $\tau_n$ is a stopping time for every $n \in \mathbb{N}$,
  \item $\tau_n$ is non-decreasing and $\tau_n \to \infty$ as $n \to \infty$ (a.s.),
  \item for all $n \in \mathbb{N}$, the stopped and centered process $M^{\tau_n} - M_0$ is a martingale with respect to $\mathcal{F}$.
\end{itemize}
\end{definition}


\begin{definition}\label{def:quadraticVariation}
  \uses{def:localMartingale}
For any continuous local martingale $M$, there exists a continuous process $[M]$ with $[M]_0 = 0$ such that $M^2 - [M]$ is a local martingale. That process is a.s. unique and is called the \emph{quadratic variation} of $M$.
\end{definition}


\begin{definition}\label{def:covariation}
  \uses{def:localMartingale}
For any continuous local martingales $M$ and $N$, there exists a continuous process $[M,N]$ with $[M,N]_0 = 0$ such that $MN - [M,N]$ is a local martingale. That process is a.s. unique and is called the \emph{covariation} of $M$ and $N$.
\end{definition}


\begin{definition}\label{def:continuousSemiMartingale}
  \uses{def:localMartingale}
A continuous semi-martingale is a process that can be decomposed into a local martingale and a finite variation process.
More formally, a process $X : \mathbb{R}_+ \to \Omega \to E$ is a continuous semi-martingale if there exists a continuous local martingale $M$ and a continuous adapted process $A$ with locally finite variation and $A_0 = 0$ such that
\begin{align*}
  X_t = M_t + A_t
\end{align*}
for all $t \ge 0$.
The decomposition is a.s. unique.
\end{definition}


\section{Stochastic integral}


\begin{definition}\label{def:predictableStepProcess}
  \uses{def:IsStoppingTime}
Let $(\tau_n)_{n \in \mathbb{N}}$ be a sequence of stopping times which is a.s. non-decreasing and such that $\tau_n \to \infty$ as $n \to \infty$.
Let $(\eta_n)_{n \in \mathbb{N}}$ be a sequence of $\mathcal{F}_{\tau_n}$-measurable random variables.
Then the predictable step process for that sequence is the process $V : \mathbb{R}_+ \to \Omega \to E$ defined by
\begin{align*}
  V_t = \sum_{n=0}^\infty \eta_n \mathbb{1}_{(\tau_n, \tau_{n+1}]}(t)
  \: .
\end{align*}
\end{definition}


\begin{definition}\label{def:elementaryStochasticIntegral}
  \uses{def:predictableStepProcess}
Let $V$ be a predictable step process and let $X$ be a stochastic process.
The \emph{elementary stochastic integral} process $V \cdot X : \mathbb{R}_+ \to \Omega \to E$ is defined by
\begin{align*}
  (V \cdot X)_t
  &= \sum_{n=0}^\infty \eta_n (X^t_{\tau_{n+1}} - X^t_{\tau_n})
  \: .
\end{align*}
\end{definition}



\section{Itô formula}


\begin{theorem}[Integration by parts]\label{thm:integration_by_parts}
  \uses{def:continuousSemiMartingale}
Let $X$ and $Y$ be two continuous semi-martingales. Then we have almost surely
\begin{align*}
  X_t Y_t - X_0 Y_0
  = (X \cdot Y)_t + (Y \cdot X)_t + [X,Y]_t
  \: .
\end{align*}
\end{theorem}

\begin{proof}

\end{proof}


\begin{theorem}\label{thm:Ito_formula}
  \uses{def:continuousSemiMartingale}
Let $X^1, \ldots, X^d$ be continuous semi-martingales and let $f : \mathbb{R}^d \to \mathbb{R}$ be a twice continuously differentiable function.
Then, writing $X = (X^1, \ldots, X^d)$, the process $f(X)$ is a semi-martingale and we have
\begin{align*}
  f(X_t)
  &= f(X_0)
  + \sum_{i=1}^d \int_0^t \frac{\partial f}{\partial x_i}(X_s) \: dX^i_s
  + \frac{1}{2} \sum_{i,j=1}^d \int_0^t \frac{\partial^2 f}{\partial x_i \partial x_j}(X_s) \: d[X^i, X^j]_s
  \: .
\end{align*}
\end{theorem}

\begin{proof}
  \uses{thm:integration_by_parts}

\end{proof}
